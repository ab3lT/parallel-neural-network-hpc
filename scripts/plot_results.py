#!/usr/bin/env python3
"""
plot_results.py - Generate performance comparison graphs

This script reads the CSV metrics files generated by the parallel DNN implementations
and creates comparison plots for the technical report.

Usage:
    python scripts/plot_results.py [--output-dir <dir>]

The script looks for CSV files in the current directory:
    - serial_metrics.csv
    - openmp_*threads_metrics.csv
    - mpi_*procs_metrics.csv
    - hybrid_*procs_*threads_metrics.csv

Output:
    - loss_comparison.png      - Training loss over epochs
    - accuracy_comparison.png  - Training accuracy over epochs
    - time_per_epoch.png       - Time per epoch comparison
    - speedup_comparison.png   - Speedup bar chart
    - total_time_comparison.png - Total training time bar chart
    - all_metrics.png          - Combined figure with all plots

Requirements:
    pip install matplotlib pandas numpy
"""

import os
import sys
import glob
import argparse
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator

# Set style for better-looking plots
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 11
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['legend.fontsize'] = 10
plt.rcParams['lines.linewidth'] = 2
plt.rcParams['lines.markersize'] = 6


def find_metrics_files(directory='.'):
    """Find all metrics CSV files in the directory."""
    files = {}
    
    # Serial
    serial_file = os.path.join(directory, 'serial_metrics.csv')
    if os.path.exists(serial_file):
        files['Serial'] = serial_file
    
    # OpenMP files
    for f in glob.glob(os.path.join(directory, 'openmp_*threads_metrics.csv')):
        match = re.search(r'openmp_(\d+)threads', f)
        if match:
            threads = match.group(1)
            files[f'OpenMP ({threads} threads)'] = f
    
    # MPI files
    for f in glob.glob(os.path.join(directory, 'mpi_*procs_metrics.csv')):
        match = re.search(r'mpi_(\d+)procs', f)
        if match:
            procs = match.group(1)
            files[f'MPI ({procs} procs)'] = f
    
    # Hybrid files
    for f in glob.glob(os.path.join(directory, 'hybrid_*procs_*threads_metrics.csv')):
        match = re.search(r'hybrid_(\d+)procs_(\d+)threads', f)
        if match:
            procs, threads = match.groups()
            files[f'Hybrid ({procs}×{threads})'] = f
    
    return files


def load_metrics(files):
    """Load all metrics files into a dictionary of DataFrames."""
    data = {}
    for name, filepath in files.items():
        try:
            df = pd.read_csv(filepath)
            data[name] = df
            print(f"  Loaded: {name} ({len(df)} epochs)")
        except Exception as e:
            print(f"  Warning: Could not load {filepath}: {e}")
    return data


def get_colors(n):
    """Get a list of distinct colors for plotting."""
    colors = [
        '#1f77b4',  # blue
        '#ff7f0e',  # orange
        '#2ca02c',  # green
        '#d62728',  # red
        '#9467bd',  # purple
        '#8c564b',  # brown
        '#e377c2',  # pink
        '#7f7f7f',  # gray
        '#bcbd22',  # olive
        '#17becf',  # cyan
    ]
    return colors[:n]


def plot_loss_comparison(data, output_dir):
    """Plot training loss over epochs for all implementations."""
    fig, ax = plt.subplots(figsize=(10, 6))
    
    colors = get_colors(len(data))
    markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', 'h', '*']
    
    for (name, df), color, marker in zip(data.items(), colors, markers):
        ax.plot(df['epoch'], df['loss'], label=name, color=color, 
                marker=marker, markevery=max(1, len(df)//10))
    
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Training Loss')
    ax.set_title('Training Loss Comparison')
    ax.legend(loc='upper right')
    ax.xaxis.set_major_locator(MaxNLocator(integer=True))
    
    plt.tight_layout()
    filepath = os.path.join(output_dir, 'loss_comparison.png')
    plt.savefig(filepath, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Saved: {filepath}")


def plot_accuracy_comparison(data, output_dir):
    """Plot training accuracy over epochs for all implementations."""
    fig, ax = plt.subplots(figsize=(10, 6))
    
    colors = get_colors(len(data))
    markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', 'h', '*']
    
    for (name, df), color, marker in zip(data.items(), colors, markers):
        accuracy = df['accuracy'] * 100  # Convert to percentage
        ax.plot(df['epoch'], accuracy, label=name, color=color,
                marker=marker, markevery=max(1, len(df)//10))
    
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Training Accuracy (%)')
    ax.set_title('Training Accuracy Comparison')
    ax.legend(loc='lower right')
    ax.xaxis.set_major_locator(MaxNLocator(integer=True))
    ax.set_ylim([0, 105])
    
    plt.tight_layout()
    filepath = os.path.join(output_dir, 'accuracy_comparison.png')
    plt.savefig(filepath, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Saved: {filepath}")


def plot_time_per_epoch(data, output_dir):
    """Plot time per epoch for all implementations."""
    fig, ax = plt.subplots(figsize=(10, 6))
    
    colors = get_colors(len(data))
    markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', 'h', '*']
    
    for (name, df), color, marker in zip(data.items(), colors, markers):
        ax.plot(df['epoch'], df['time'], label=name, color=color,
                marker=marker, markevery=max(1, len(df)//10))
    
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Time (seconds)')
    ax.set_title('Time per Epoch Comparison')
    ax.legend(loc='upper right')
    ax.xaxis.set_major_locator(MaxNLocator(integer=True))
    
    plt.tight_layout()
    filepath = os.path.join(output_dir, 'time_per_epoch.png')
    plt.savefig(filepath, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Saved: {filepath}")


def plot_speedup_comparison(data, output_dir):
    """Plot speedup bar chart comparing all implementations."""
    if 'Serial' not in data:
        print("  Warning: Serial baseline not found, cannot compute speedup")
        return
    
    serial_time = data['Serial']['time'].sum()
    
    names = []
    speedups = []
    
    for name, df in data.items():
        total_time = df['time'].sum()
        speedup = serial_time / total_time
        names.append(name)
        speedups.append(speedup)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    colors = get_colors(len(names))
    bars = ax.bar(names, speedups, color=colors, edgecolor='black', linewidth=1)
    
    # Add value labels on bars
    for bar, speedup in zip(bars, speedups):
        height = bar.get_height()
        ax.annotate(f'{speedup:.2f}×',
                    xy=(bar.get_x() + bar.get_width() / 2, height),
                    xytext=(0, 3),
                    textcoords="offset points",
                    ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    ax.set_xlabel('Implementation')
    ax.set_ylabel('Speedup (relative to Serial)')
    ax.set_title('Speedup Comparison')
    ax.axhline(y=1.0, color='red', linestyle='--', linewidth=1, label='Baseline (1×)')
    
    # Rotate x-axis labels if needed
    plt.xticks(rotation=15, ha='right')
    
    plt.tight_layout()
    filepath = os.path.join(output_dir, 'speedup_comparison.png')
    plt.savefig(filepath, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Saved: {filepath}")


def plot_total_time_comparison(data, output_dir):
    """Plot total training time bar chart."""
    names = []
    times = []
    
    for name, df in data.items():
        total_time = df['time'].sum()
        names.append(name)
        times.append(total_time)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    colors = get_colors(len(names))
    bars = ax.bar(names, times, color=colors, edgecolor='black', linewidth=1)
    
    # Add value labels on bars
    for bar, time in zip(bars, times):
        height = bar.get_height()
        ax.annotate(f'{time:.1f}s',
                    xy=(bar.get_x() + bar.get_width() / 2, height),
                    xytext=(0, 3),
                    textcoords="offset points",
                    ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    ax.set_xlabel('Implementation')
    ax.set_ylabel('Total Training Time (seconds)')
    ax.set_title('Total Training Time Comparison')
    
    # Rotate x-axis labels if needed
    plt.xticks(rotation=15, ha='right')
    
    plt.tight_layout()
    filepath = os.path.join(output_dir, 'total_time_comparison.png')
    plt.savefig(filepath, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Saved: {filepath}")


def plot_combined_figure(data, output_dir):
    """Create a combined figure with all plots for the report."""
    if 'Serial' not in data:
        serial_time = None
    else:
        serial_time = data['Serial']['time'].sum()
    
    fig = plt.figure(figsize=(16, 12))
    
    colors = get_colors(len(data))
    markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', 'h', '*']
    
    # 1. Loss comparison (top-left)
    ax1 = fig.add_subplot(2, 2, 1)
    for (name, df), color, marker in zip(data.items(), colors, markers):
        ax1.plot(df['epoch'], df['loss'], label=name, color=color,
                 marker=marker, markevery=max(1, len(df)//10))
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Training Loss')
    ax1.set_title('(a) Training Loss')
    ax1.legend(loc='upper right', fontsize=8)
    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))
    
    # 2. Accuracy comparison (top-right)
    ax2 = fig.add_subplot(2, 2, 2)
    for (name, df), color, marker in zip(data.items(), colors, markers):
        accuracy = df['accuracy'] * 100
        ax2.plot(df['epoch'], accuracy, label=name, color=color,
                 marker=marker, markevery=max(1, len(df)//10))
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Training Accuracy (%)')
    ax2.set_title('(b) Training Accuracy')
    ax2.legend(loc='lower right', fontsize=8)
    ax2.xaxis.set_major_locator(MaxNLocator(integer=True))
    ax2.set_ylim([0, 105])
    
    # 3. Time per epoch (bottom-left)
    ax3 = fig.add_subplot(2, 2, 3)
    for (name, df), color, marker in zip(data.items(), colors, markers):
        ax3.plot(df['epoch'], df['time'], label=name, color=color,
                 marker=marker, markevery=max(1, len(df)//10))
    ax3.set_xlabel('Epoch')
    ax3.set_ylabel('Time (seconds)')
    ax3.set_title('(c) Time per Epoch')
    ax3.legend(loc='upper right', fontsize=8)
    ax3.xaxis.set_major_locator(MaxNLocator(integer=True))
    
    # 4. Speedup comparison (bottom-right)
    ax4 = fig.add_subplot(2, 2, 4)
    names = list(data.keys())
    if serial_time:
        speedups = [serial_time / df['time'].sum() for df in data.values()]
    else:
        # Just show relative times if no serial baseline
        max_time = max(df['time'].sum() for df in data.values())
        speedups = [max_time / df['time'].sum() for df in data.values()]
    
    bars = ax4.bar(range(len(names)), speedups, color=colors, edgecolor='black')
    for bar, speedup in zip(bars, speedups):
        height = bar.get_height()
        ax4.annotate(f'{speedup:.2f}×',
                     xy=(bar.get_x() + bar.get_width() / 2, height),
                     xytext=(0, 3), textcoords="offset points",
                     ha='center', va='bottom', fontsize=9, fontweight='bold')
    ax4.set_xticks(range(len(names)))
    ax4.set_xticklabels(names, rotation=20, ha='right', fontsize=9)
    ax4.set_ylabel('Speedup')
    ax4.set_title('(d) Speedup Comparison')
    ax4.axhline(y=1.0, color='red', linestyle='--', linewidth=1)
    
    plt.tight_layout()
    filepath = os.path.join(output_dir, 'all_metrics.png')
    plt.savefig(filepath, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Saved: {filepath}")


def plot_scalability(data, output_dir):
    """Plot scalability analysis (if multiple configurations exist)."""
    # Extract OpenMP scalability data
    openmp_data = {}
    for name, df in data.items():
        match = re.search(r'OpenMP \((\d+) threads\)', name)
        if match:
            threads = int(match.group(1))
            openmp_data[threads] = df['time'].sum()
    
    # Extract MPI scalability data
    mpi_data = {}
    for name, df in data.items():
        match = re.search(r'MPI \((\d+) procs\)', name)
        if match:
            procs = int(match.group(1))
            mpi_data[procs] = df['time'].sum()
    
    if len(openmp_data) < 2 and len(mpi_data) < 2:
        print("  Skipping scalability plot (need multiple configurations)")
        return
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    # Get serial baseline
    serial_time = data.get('Serial', pd.DataFrame({'time': [1]}))['time'].sum()
    
    # OpenMP scalability
    if len(openmp_data) >= 2:
        threads = sorted(openmp_data.keys())
        times = [openmp_data[t] for t in threads]
        speedups = [serial_time / t for t in times]
        
        ax1.plot(threads, speedups, 'o-', color='#1f77b4', linewidth=2, 
                 markersize=8, label='Actual')
        ax1.plot(threads, threads, '--', color='gray', linewidth=1, 
                 label='Ideal (linear)')
        ax1.set_xlabel('Number of Threads')
        ax1.set_ylabel('Speedup')
        ax1.set_title('OpenMP Strong Scaling')
        ax1.legend()
        ax1.set_xticks(threads)
    else:
        ax1.text(0.5, 0.5, 'Insufficient data\nfor OpenMP scaling',
                 ha='center', va='center', transform=ax1.transAxes)
        ax1.set_title('OpenMP Strong Scaling')
    
    # MPI scalability
    if len(mpi_data) >= 2:
        procs = sorted(mpi_data.keys())
        times = [mpi_data[p] for p in procs]
        speedups = [serial_time / t for t in times]
        
        ax2.plot(procs, speedups, 's-', color='#ff7f0e', linewidth=2,
                 markersize=8, label='Actual')
        ax2.plot(procs, procs, '--', color='gray', linewidth=1,
                 label='Ideal (linear)')
        ax2.set_xlabel('Number of Processes')
        ax2.set_ylabel('Speedup')
        ax2.set_title('MPI Strong Scaling')
        ax2.legend()
        ax2.set_xticks(procs)
    else:
        ax2.text(0.5, 0.5, 'Insufficient data\nfor MPI scaling',
                 ha='center', va='center', transform=ax2.transAxes)
        ax2.set_title('MPI Strong Scaling')
    
    plt.tight_layout()
    filepath = os.path.join(output_dir, 'scalability.png')
    plt.savefig(filepath, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Saved: {filepath}")


def generate_summary_table(data, output_dir):
    """Generate a summary table as CSV and text."""
    if 'Serial' in data:
        serial_time = data['Serial']['time'].sum()
    else:
        serial_time = None
    
    rows = []
    for name, df in data.items():
        total_time = df['time'].sum()
        avg_time = df['time'].mean()
        final_loss = df['loss'].iloc[-1]
        final_acc = df['accuracy'].iloc[-1] * 100
        
        if serial_time:
            speedup = serial_time / total_time
        else:
            speedup = 1.0
        
        rows.append({
            'Implementation': name,
            'Total Time (s)': f'{total_time:.2f}',
            'Avg Epoch Time (s)': f'{avg_time:.3f}',
            'Final Loss': f'{final_loss:.4f}',
            'Final Accuracy (%)': f'{final_acc:.2f}',
            'Speedup': f'{speedup:.2f}×'
        })
    
    summary_df = pd.DataFrame(rows)
    
    # Save as CSV
    csv_path = os.path.join(output_dir, 'summary_table.csv')
    summary_df.to_csv(csv_path, index=False)
    print(f"  Saved: {csv_path}")
    
    # Print to console
    print("\n" + "="*80)
    print("PERFORMANCE SUMMARY")
    print("="*80)
    print(summary_df.to_string(index=False))
    print("="*80 + "\n")
    
    return summary_df


def main():
    parser = argparse.ArgumentParser(
        description='Generate performance comparison graphs from training metrics'
    )
    parser.add_argument('--input-dir', '-i', default='.',
                        help='Directory containing metrics CSV files (default: current)')
    parser.add_argument('--output-dir', '-o', default='plots',
                        help='Directory to save plots (default: plots)')
    args = parser.parse_args()
    
    # Create output directory
    os.makedirs(args.output_dir, exist_ok=True)
    
    print("="*60)
    print("Parallel DNN Performance Analysis")
    print("="*60)
    
    # Find metrics files
    print(f"\nSearching for metrics files in: {args.input_dir}")
    files = find_metrics_files(args.input_dir)
    
    if not files:
        print("\nError: No metrics files found!")
        print("Make sure you have run the training programs first.")
        print("Expected files: serial_metrics.csv, openmp_*threads_metrics.csv, etc.")
        sys.exit(1)
    
    print(f"\nFound {len(files)} metrics file(s):")
    for name, path in files.items():
        print(f"  - {name}: {path}")
    
    # Load data
    print("\nLoading metrics data...")
    data = load_metrics(files)
    
    if not data:
        print("\nError: Could not load any metrics files!")
        sys.exit(1)
    
    # Generate plots
    print(f"\nGenerating plots in: {args.output_dir}/")
    
    plot_loss_comparison(data, args.output_dir)
    plot_accuracy_comparison(data, args.output_dir)
    plot_time_per_epoch(data, args.output_dir)
    plot_speedup_comparison(data, args.output_dir)
    plot_total_time_comparison(data, args.output_dir)
    plot_combined_figure(data, args.output_dir)
    plot_scalability(data, args.output_dir)
    
    # Generate summary table
    generate_summary_table(data, args.output_dir)
    
    print("Done! All plots have been generated.")
    print(f"\nTo include in LaTeX report:")
    print(f"  \\includegraphics[width=\\textwidth]{{plots/all_metrics.png}}")


if __name__ == '__main__':
    main()
